{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G8JILDxrsgPY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "# import matplotlib.pyplot as plot\n",
    "from random import shuffle\n",
    "#from google.colab import drive                IF you are using COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yKixUdldszgx"
   },
   "outputs": [],
   "source": [
    "# Use this if you are working on COLAB\n",
    "# This will prompt for authorization.\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HApL-cvBs1Ah"
   },
   "outputs": [],
   "source": [
    "def extract_data(x_data_filepath, y_data_filepath):\n",
    "    X = np.load(x_data_filepath)\n",
    "    y = np.load(y_data_filepath)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_mCkbFV1bq9"
   },
   "outputs": [],
   "source": [
    "def data_visualization(images,labels):\n",
    "    \"\"\"\n",
    "    Visualize 6 pictures per class using your prefered visulization library (matplotlib, etc)\n",
    "\n",
    "    Args:\n",
    "    images: training images in shape (num_images,3,image_H,image_W)\n",
    "    labels: training labels in shape (num_images,)\n",
    "    \"\"\"\n",
    "    img_labels = [int(x) for x in labels]\n",
    "    label0 = [x for x, label in enumerate(img_labels) if label == 0]\n",
    "    label1 = [x for x, label in enumerate(img_labels) if label == 1]\n",
    "    label2 = [x for x, label in enumerate(img_labels) if label == 2]\n",
    "    label3 = [x for x, label in enumerate(img_labels) if label == 3]\n",
    "    label4 = [x for x, label in enumerate(img_labels) if label == 4]\n",
    "\n",
    "    label_lst = [label0, label1, label2, label3, label4]\n",
    "\n",
    "    for i in range(6): #select the first 6 pics\n",
    "        for label in label_lst: #iterate over each label\n",
    "            plt.imshow(np.swapaxes(images[label[i]].T,0,1))\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnttiXoks2sn"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Extracting and loading data\n",
    "############################################################\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.len = len(X)           \n",
    "        if torch.cuda.is_available():\n",
    "          self.x_data = torch.from_numpy(X).float().cuda()\n",
    "          self.y_data = torch.from_numpy(y).long().cuda()\n",
    "        else:\n",
    "          self.x_data = torch.from_numpy(X).float()\n",
    "          self.y_data = torch.from_numpy(y).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2LxFInms4ks"
   },
   "outputs": [],
   "source": [
    "def create_validation(x_train,y_train):\n",
    "    \"\"\"\n",
    "    Randomly choose 20 percent of the training data as validation data.\n",
    "\n",
    "    Args:\n",
    "        x_train: training images in shape (num_images,3,image_H,image_W)\n",
    "        y_train: training labels in shape (num_images,)\n",
    "    Returns:\n",
    "        new_x_train: training images in shape (0.8*num_images,3,image_H,image_W)\n",
    "        new_y_train: training labels in shape (0.8*num_images,)\n",
    "        x_val: validation images in shape (0.2*num_images,3,image_H,image_W)\n",
    "        y_val: validation labels in shape (0.2*num_images,)\n",
    "    \"\"\"\n",
    "#     dataset = Dataset(x_train, y_train)\n",
    "    #shuffle the list of indices of the dataset - prep for the split of valid and train sets\n",
    "\n",
    "    indices = list(range(len(x_train)))\n",
    "    shuffle(indices)\n",
    "    valid_size = int(np.floor(0.2 * len(x_train)))\n",
    "#     x_val = dataset.x_data[indices[:valid_size]]\n",
    "    x_val = x_train[indices[:valid_size]]    \n",
    "#     y_val = dataset.y_data[indices[:valid_size]]\n",
    "    y_val = y_train[indices[:valid_size]]\n",
    "#     new_x_train = dataset.x_data[indices[valid_size:]]\n",
    "    new_x_train = x_train[indices[valid_size:]]\n",
    "#     new_y_train = dataset.y_data[indices[valid_size:]]\n",
    "    new_y_train = y_train[indices[valid_size:]]\n",
    "    \n",
    "    return new_x_train,new_y_train,x_val,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, y_train = extract_data('data/images_train.npy','data/labels_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# #shuffle the list of indices of the dataset - prep for the split of valid and train sets\n",
    "# x_train, y_train, x_val, y_val = create_validation(images, labels)\n",
    "# y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2081, 3, 64, 85])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "812xDSEms72t"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Feed Forward Neural Network\n",
    "############################################################\n",
    "class FeedForwardNN(nn.Module):\n",
    "    \"\"\" \n",
    "        (1) Use self.fc1 as the variable name for your first fully connected layer\n",
    "        (2) Use self.fc2 as the variable name for your second fully connected layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(FeedForwardNN,self).__init__()\n",
    "        self.fc1 = nn.Linear(16320,2000)\n",
    "        self.fc2 = nn.Linear(2000,5)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #reshape to (16320,1)\n",
    "        x_reshape = x.view(x.size(0),-1)\n",
    "        fc1_output = F.relu(self.fc1(x_reshape))\n",
    "        out = self.fc2(fc1_output)\n",
    "        return out\n",
    "\n",
    "    \"\"\" \n",
    "        Please do not change the functions below. \n",
    "        They will be used to test the correctness of your implementation \n",
    "    \"\"\"\n",
    "    def get_fc1_params(self):\n",
    "        return self.fc1.__repr__()\n",
    "    \n",
    "    def get_fc2_params(self):\n",
    "        return self.fc2.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0NXchxSvtEdz"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Convolutional Neural Network\n",
    "############################################################\n",
    "class ConvolutionalNN(nn.Module):\n",
    "    \"\"\" \n",
    "        (1) Use self.conv1 as the variable name for your first convolutional layer\n",
    "        (2) Use self.pool1 as the variable name for your first pooling layer\n",
    "        (3) Use self.conv2 as the variable name for your second convolutional layer\n",
    "        (4) Use self.pool2 as the variable name for you second pooling layer  \n",
    "        (5) Use self.fc1 as the variable name for your first fully connected laye\n",
    "        (6) Use self.fc2 as the variable name for your second fully connected layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNN, self).__init__()\n",
    "        \n",
    "        #cnn\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size = 3)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size = 3)\n",
    "        #maxpooling 2d\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 2)\n",
    "        #fully connected layer\n",
    "        self.fc1 = nn.Linear(8512, 200)\n",
    "        self.fc2 = nn.Linear(200, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_np = x.numpy()\n",
    "        x = normalize_image(x)\n",
    "        #relu + maxpool first layer\n",
    "        relu1 = F.relu(self.cnn1(x))\n",
    "        maxpooling1 = self.pool1(relu1)\n",
    "        #relu + maxpool second layer\n",
    "        relu2 = F.relu(self.cnn2(maxpooling1))\n",
    "        maxpooling2 = self.pool2(relu2)\n",
    "        #flatten image\n",
    "        reshape = maxpooling2.view(maxpooling2.size(0),-1)\n",
    "        #fully connected layer - output\n",
    "        fc1_output = F.relu(self.fc1(reshape))\n",
    "        out = self.fc2(fc1_output)\n",
    "        return out\n",
    "      \n",
    "    \"\"\" \n",
    "        Please do not change the functions below. \n",
    "        They will be used to test the correctness of your implementation\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_conv1_params(self):\n",
    "        return self.conv1.__repr__()\n",
    "    \n",
    "    def get_pool1_params(self):\n",
    "        return self.pool1.__repr__()\n",
    "\n",
    "    def get_conv2_params(self):\n",
    "        return self.conv2.__repr__()\n",
    "      \n",
    "    def get_pool2_params(self):\n",
    "        return self.pool2.__repr__()\n",
    "      \n",
    "    def get_fc1_params(self):\n",
    "        return self.fc1.__repr__()\n",
    "    \n",
    "    def get_fc2_params(self):\n",
    "        return self.fc2.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5hhOy6htEtC"
   },
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normalize each input image\n",
    "\n",
    "    Args:\n",
    "        image: the input image in shape (3,image_H,image_W)\n",
    "    Returns:\n",
    "        norimg: the normalized image in the same shape as the input\n",
    "    \"\"\"\n",
    "#     image = image.numpy()\n",
    "    \n",
    "    rbg_mean = []\n",
    "    rbg_std = []\n",
    "    for i in range(0,3):\n",
    "        mean =  np.mean(image[i,:,:])\n",
    "        std = np.std(image[i,:,:])\n",
    "        image[i,:,:] = (image[i,:,:] - mean)/std\n",
    "    \n",
    "    norimg = image\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    return (norimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aVRyEtmQtzn2"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Optimized Neural Network\n",
    "############################################################\n",
    "class OptimizedNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OptimizedNN, self).__init__()\n",
    "        #cnn\n",
    "        self.cnn1 = nn.Conv2d(3, 16, kernel_size = 3)\n",
    "        self.cnn2 = nn.Conv2d(16, 32, kernel_size = 3)\n",
    "        self.cnn3 = nn.Conv2d(32, 64, kernel_size = 3)\n",
    "        #maxpooling 2d\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2)\n",
    "        #fully connected layer\n",
    "        self.fc1 = nn.Linear(3072, 200)\n",
    "        self.fc2 = nn.Linear(200, 5)\n",
    "        #dropout\n",
    "        self.drop_out1 = nn.Dropout(p = 0.5)\n",
    "        self.drop_out2 = nn.Dropout(p = 0.5)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         x_np = x.numpy()\n",
    "#         x = normalize_image(x)\n",
    "#         print(type(x))\n",
    "#         x = torch.from_numpy(x)\n",
    "        #relu + maxpool first layer\n",
    "        relu1 = F.relu(self.cnn1(x))\n",
    "        maxpooling1 = self.pool(relu1)\n",
    "        \n",
    "        #relu + maxpool second layer\n",
    "        relu2 = F.relu(self.cnn2(maxpooling1))\n",
    "        maxpooling2 = self.pool(relu2)\n",
    "        \n",
    "        #relu + maxpool second layer\n",
    "        relu3 = F.relu(self.cnn3(maxpooling2))\n",
    "        maxpooling3 = self.pool(relu3)\n",
    "        \n",
    "        #flatten image\n",
    "        reshape = maxpooling3.view(maxpooling3.size(0),-1)\n",
    "        #fully connected layer - output\n",
    "        fc1_output = self.drop_out1(reshape)\n",
    "        fc1_output = F.relu(self.fc1(fc1_output))\n",
    "        fc2_output = self.drop_out2(fc1_output)\n",
    "        out = self.fc2(fc2_output)\n",
    "        \n",
    "        return out\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nQHzqYLSt-mQ"
   },
   "outputs": [],
   "source": [
    "def train_val_NN(neural_network, train_loader, validation_loader, loss_function, optimizer,num_epochs):\n",
    "    \"\"\"\n",
    "    Runs experiment on the model neural network given a train loader, loss function and optimizer and find validation accuracy for each epoch given the validation_loader.\n",
    "\n",
    "    Args:\n",
    "        neural_network (NN model that extends torch.nn.Module): For example, it should take an instance of either\n",
    "                                                                FeedForwardNN or ConvolutionalNN,\n",
    "        train_loader (DataLoader),\n",
    "        validation_loader (DataLoader),\n",
    "        loss_function (torch.nn.CrossEntropyLoss),\n",
    "        optimizer (optim.SGD)\n",
    "        num_epochs (number of iterations)\n",
    "    Returns:\n",
    "        tuple: First position, training accuracies of each epoch formatted in an array of shape (num_epochs,1).\n",
    "               Second position, training loss of each epoch formatted in an array of shape (num_epochs,1).\n",
    "               third position, validation accuracy of each epoch formatted in an array of shape (num_epochs,1).\n",
    "               \n",
    "    \"\"\"\n",
    "    #initialize variables\n",
    "    accuracy = np.zeros((num_epochs, 1))\n",
    "    loss_np = np.zeros((num_epochs,1))\n",
    "    val_accuracy = np.zeros((num_epochs, 1))\n",
    "    iter_num = 0\n",
    "    \n",
    "    ########################## TRAINING SET ########################## \n",
    "    for epoch in range(num_epochs):\n",
    "        training_loss = []\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        neural_network.train()\n",
    "        for i, data in enumerate(train_loader,0):\n",
    "            #get the inputs\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "             \n",
    "            # forward + backward + optimize\n",
    "            outputs = neural_network(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_loss.append(loss.item())\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (pred == labels).sum().item()\n",
    "            \n",
    "        #calculate the accuracy rate for each epoch    \n",
    "        accuracy[iter_num] =  correct/total\n",
    "        loss_np[iter_num] = np.mean(training_loss)\n",
    "\n",
    "        \n",
    "        ########################## EVALUATION SET ########################## \n",
    "        #re-initialize 'correct'\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        neural_network.eval()\n",
    "        for i, data in enumerate(validation_loader,0):\n",
    "            #get the inputs\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            outputs = neural_network(inputs)\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (pred == labels).sum().item()\n",
    "        val_accuracy[iter_num] = correct/total\n",
    "        \n",
    "        iter_num +=1\n",
    "        \n",
    "  \n",
    "    return accuracy,loss_np,val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLlMhNt7vQxR"
   },
   "outputs": [],
   "source": [
    "def test_NN(neural_network, test_loader):\n",
    "  \n",
    "    \"\"\"\n",
    "    Runs experiment on the model neural network given a test loader, loss function and optimizer.\n",
    "\n",
    "    Args:\n",
    "        neural_network (NN model that extends torch.nn.Module): For example, it should take an instance of either\n",
    "                                                                FeedForwardNN or ConvolutionalNN,\n",
    "        test_loader (DataLoader), (make sure the loader is not shuffled)\n",
    "        loss_function (torch.nn.CrossEntropyLoss),\n",
    "        optimizer (your choice)\n",
    "        num_epochs (number of iterations)\n",
    "    Returns:\n",
    "        your predictions         \n",
    "    \"\"\"\n",
    "    \n",
    "    neural_network.eval()\n",
    "    Preds = torch.LongTensor()\n",
    "\n",
    "    for _, data in enumerate(test_loader):\n",
    "        data = data[0]\n",
    "        outputs = neural_network(data)\n",
    "#         pred,_ = torch.max(outputs.data, 1)\n",
    "        _,pred = torch.max(outputs.data, 1)\n",
    "#         _,pred= outputs.data.max(1, keepdim = True)\n",
    "        Preds = torch.cat((Preds, pred), dim = 0)\n",
    "  \n",
    "    return Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OptimizedNN()\n",
    "test = np.load('data/images_test.npy')\n",
    "test = torch.tensor(test, dtype = torch.float32)\n",
    "test = torch.utils.data.TensorDataset(test)\n",
    "\n",
    "test_loader = DataLoader(test, batch_size = 32)\n",
    "# print(test_loader)\n",
    "Preds = test_NN(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('HW4_preds.txt','w', encoding = 'utf8') as file:\n",
    "#     for i in range(len(test_loader.dataset)):\n",
    "#         file.write(str(Preds[i].item())+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lDQrfJXSv9iY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4       ]\n",
      " [0.41153846]\n",
      " [0.41538462]\n",
      " [0.425     ]\n",
      " [0.43653846]\n",
      " [0.43461538]\n",
      " [0.44615385]\n",
      " [0.44615385]\n",
      " [0.45192308]\n",
      " [0.45192308]\n",
      " [0.46153846]\n",
      " [0.46153846]\n",
      " [0.46153846]\n",
      " [0.46153846]\n",
      " [0.46153846]\n",
      " [0.46730769]\n",
      " [0.46923077]\n",
      " [0.46923077]\n",
      " [0.47115385]\n",
      " [0.47115385]\n",
      " [0.47307692]\n",
      " [0.475     ]\n",
      " [0.47115385]\n",
      " [0.47307692]\n",
      " [0.475     ]\n",
      " [0.475     ]\n",
      " [0.47692308]\n",
      " [0.47692308]\n",
      " [0.47884615]\n",
      " [0.48076923]\n",
      " [0.48846154]\n",
      " [0.49423077]\n",
      " [0.49807692]\n",
      " [0.49230769]\n",
      " [0.49423077]\n",
      " [0.49423077]\n",
      " [0.5       ]\n",
      " [0.5       ]\n",
      " [0.49807692]\n",
      " [0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "# Run Baseline FeedForward\n",
    "# images, labels = extract_data('data/images_train.npy','data/labels_train.npy')\n",
    "# x_train, y_train, x_val, y_val = create_validation(images, labels)\n",
    "# train_set = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "# val_set = torch.utils.data.TensorDataset(x_val, y_val)\n",
    "# train_loader = DataLoader(train_set, batch_size = 64)\n",
    "# validation_loader = DataLoader(val_set, batch_size = 64)\n",
    "\n",
    "# num_epochs = 40\n",
    "# ff_nn= FeedForwardNN()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adagrad(ff_nn.parameters(), lr = 0.001)\n",
    "\n",
    "# accuracy1,loss_np1,val_accuracy1 = train_val_NN(ff_nn, train_loader, validation_loader, criterion, optimizer,num_epochs)\n",
    "# print(val_accuracy1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy_lst = [accuracy1[i].tolist()[0] for i in range(len(accuracy1))]\n",
    "# loss_lst = [loss_np1[i].tolist()[0] for i in range(len(loss_np1))]\n",
    "# epochs = [i+1 for i in range(num_epochs)]\n",
    "# p1, ax = plt.subplots(1)\n",
    "# # ax.set_ylim(bottom = 0)\n",
    "# ax.plot(epochs, accuracy_lst, marker = 'o')\n",
    "# ax.plot(epochs, loss_lst, 'r', marker = 's')\n",
    "# plt.show(p1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DK0rXwRdv-PC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39230769]\n",
      " [0.39615385]\n",
      " [0.41346154]\n",
      " [0.44807692]\n",
      " [0.45961538]\n",
      " [0.48269231]\n",
      " [0.49807692]\n",
      " [0.51153846]\n",
      " [0.52307692]\n",
      " [0.52884615]\n",
      " [0.53461538]\n",
      " [0.54038462]\n",
      " [0.54423077]\n",
      " [0.54423077]\n",
      " [0.54423077]\n",
      " [0.55384615]\n",
      " [0.55769231]\n",
      " [0.55961538]\n",
      " [0.56153846]\n",
      " [0.56153846]\n",
      " [0.56346154]\n",
      " [0.56346154]\n",
      " [0.56346154]\n",
      " [0.56346154]\n",
      " [0.56923077]\n",
      " [0.57115385]\n",
      " [0.575     ]\n",
      " [0.58076923]\n",
      " [0.58076923]\n",
      " [0.58269231]\n",
      " [0.58269231]\n",
      " [0.58846154]\n",
      " [0.59038462]\n",
      " [0.59423077]\n",
      " [0.59615385]\n",
      " [0.59423077]\n",
      " [0.59423077]\n",
      " [0.59807692]\n",
      " [0.6       ]\n",
      " [0.6       ]]\n"
     ]
    }
   ],
   "source": [
    "# Run Baseline CNN\n",
    "# images, labels = extract_data('data/images_train.npy','data/labels_train.npy')\n",
    "# x_train, y_train, x_val, y_val = create_validation(images, labels)\n",
    "# train_set = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "# val_set = torch.utils.data.TensorDataset(x_val, y_val)\n",
    "# train_loader = DataLoader(train_set, batch_size = 64)\n",
    "# validation_loader = DataLoader(val_set, batch_size = 64)\n",
    "\n",
    "# num_epochs = 40\n",
    "# cnn= ConvolutionalNN()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adagrad(cnn.parameters(), lr = 0.001)\n",
    "\n",
    "# accuracy2,loss_np2,val_accuracy2 = train_val_NN(cnn, train_loader, validation_loader, criterion, optimizer,num_epochs)\n",
    "# print(val_accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy_lst2 = [accuracy2[i].tolist()[0] for i in range(len(accuracy2))]\n",
    "# loss_lst2 = [loss_np2[i].tolist()[0] for i in range(len(loss_np2))]\n",
    "# epochs = [i+1 for i in range(num_epochs)]\n",
    "# p2, ax = plt.subplots(1)\n",
    "# ax.plot(epochs, accuracy_lst2, marker = 'o')\n",
    "# ax.plot(epochs, loss_lst2, 'r', marker = 's')\n",
    "# plt.show(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gojhzqhrwAxk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39807692]\n",
      " [0.40576923]\n",
      " [0.41346154]\n",
      " [0.42115385]\n",
      " [0.41923077]\n",
      " [0.42692308]\n",
      " [0.44615385]\n",
      " [0.45769231]\n",
      " [0.48269231]\n",
      " [0.48653846]\n",
      " [0.49807692]\n",
      " [0.51153846]\n",
      " [0.51153846]\n",
      " [0.52692308]\n",
      " [0.53076923]\n",
      " [0.52884615]\n",
      " [0.53269231]\n",
      " [0.54038462]\n",
      " [0.54615385]\n",
      " [0.54807692]\n",
      " [0.55      ]\n",
      " [0.55192308]\n",
      " [0.55384615]\n",
      " [0.55576923]\n",
      " [0.56153846]\n",
      " [0.56153846]\n",
      " [0.56538462]\n",
      " [0.56923077]\n",
      " [0.575     ]\n",
      " [0.57884615]\n",
      " [0.58076923]\n",
      " [0.58269231]\n",
      " [0.57884615]\n",
      " [0.58076923]\n",
      " [0.57884615]\n",
      " [0.58076923]\n",
      " [0.57884615]\n",
      " [0.58076923]\n",
      " [0.58653846]\n",
      " [0.58653846]]\n"
     ]
    }
   ],
   "source": [
    "# Run Baseline CNN on Normilized Images\n",
    "# images, labels = extract_data('data/images_train.npy','data/labels_train.npy')\n",
    "# x_train, y_train, x_val, y_val = create_validation(images, labels)\n",
    "# train_set = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "# val_set = torch.utils.data.TensorDataset(x_val, y_val)\n",
    "# train_loader = DataLoader(train_set, batch_size = 64)\n",
    "# validation_loader = DataLoader(val_set, batch_size = 64)\n",
    "\n",
    "# num_epochs = 40\n",
    "# cnn= ConvolutionalNN()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adagrad(cnn.parameters(), lr = 0.001)\n",
    "\n",
    "# accuracy3,loss_np3,val_accuracy3 = train_val_NN(cnn, train_loader, validation_loader, criterion, optimizer,num_epochs)\n",
    "# print(val_accuracy3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAG+xJREFUeJzt3XmUVPWZ//H3000DHURapEXoZtHoqLgEsM3okBjGREXGEde4RI2/ieE3/sY54xlB0CQGzTgqiUQ944aOP5zFHYKM4q6RmRgNGGVXJIphB2UV2br7mT+q2jTdt25Vd223bn1e5/Sh635vVz3cAx++PPd77zV3R0RE4qWi2AWIiEjuKdxFRGJI4S4iEkMKdxGRGFK4i4jEkMJdRCSGFO4iIjGkcBcRiSGFu4hIDHUp1gf36dPHBw8eXKyPFxEpSe+8886n7l6bbr+ihfvgwYOZN29esT5eRKQkmdknmeyntoyISAwp3EVEYkjhLiISQwp3EZEYUriLiMRQ6YT7wQeDWfuvgw8udmUiIpFTOuG+fn3HtouIlLHSCXcREcmYwl1EJIYU7iIiMaRwFxGJodIJ9759O7ZdRKSMlU64r1sH7n/6+ud/Tmx/6aXi1iUiEkGlE+5t/e3fQo8ecMcdxa5ERCRySjfcDzgArrwSHn0UVq0qdjUiIpFSuuEOcM010NwMd99d7EpERCKltMN98GC44AJ44AHYtq3Y1YiIREZphzvAuHGJYH/wwWJXIiISGaUf7g0NMHIk3Hkn7N1b7GpERCIhbbib2cNmtsHMFqXZ7wQzazSz83NXXobGj0+cVH3iiYJ/tIhIFGUyc58GjArbwcwqgduB4iw6HzUKhgyBX/wisQZeRKTMpQ13d58DbEqz298D04ENuSiqwyoq4NprYf58eOWVopQgIhIlWffczawOOAe4L4N9x5rZPDObt3Hjxmw/el833JD49bTT9DAPESl7uTiheicwwd2b0+3o7lPdvcHdG2pra3Pw0a3oYR4iIl/qkoP3aAAeNzOAPsBoM2t095k5eG8REemErMPd3Q9p+d7MpgHPKthFRIorbbib2WPASKCPma0CfgpUAbj7/XmtTkREOiVtuLv7xZm+mbtfkVU1+dLUBJWVxa5CRKRgSv8K1RZhD+248ELYvbtwtYiIFFl8wr3twzxavn75S5g+HUaPhu3bi12liEhB5GK1TLRdcw0ceCBcfjnsv3/78b59E/8wiIjESHxm7mEuuyz1mNbBi0gMlUe4i4iUGYW7iEgMKdwBHntMd5MUkVhRuANccglUV+97wzHdeExESlj5hHuqdfB9+8Ltt6deB68TriJSguK/FLJFuuWOEyYUpg4RkQIon5m7iEgZUbhn4rnnEr139eRFpESUT1smG2eemXpMPXkRiSDN3FuEnXCdPLmwtYiIZEkz9xbpTrhed11h6hARyQHN3HNBF0CJSMQo3HOhWzedbBWRSFG4ZypVT75nT9i7N3hMJ1tFpEjUc89UWE/erHB1iIhkQDP3fNPsXUSKQOGeb4ceCvvtp568iBSUwj3fxoyBHTuCxzSrF5E8UbjnQtgFUI8+WthaRETQCdXcyOYB2zt3Ju4lLyKSQ5q5F9tXvwr776+evIjklMK92A47DLZvDx5TT15EOknhXghhPfk33ihsLSJSFtKGu5k9bGYbzGxRivHvmdkCM1toZm+a2ddyX2aJW7cucf+Ztl/r1qW/AGr9et1LXkQ6LJOZ+zRgVMj4x8C33P1Y4GfA1BzUJS0GDUrdnlHbRkRSSBvu7j4H2BQy/qa7b06+fAuoz1FtAnDFFcWuQERKUK577j8Ans/xe8ZfWE/+/vsLW4uIxELOwt3M/pJEuE8I2Wesmc0zs3kbN27M1UeXvrCefDrXXQe1terJi8g+chLuZnYc8BAwxt0/S7Wfu0919wZ3b6itrc3FR8uUKfDpp8Fj6smLlK2sw93MBgIzgMvcfVn2JUk7YW2bFSsKWoqIlIa0tx8ws8eAkUAfM1sF/BSoAnD3+4EbgQOBey2xrK/R3RvyVXBZyub2Br17w+bN7bf37Zvd+4pIpKUNd3e/OM34lcCVOatIciso2EEtG5GY0xWqIiIxpHCPg7CefJhx46BPH620EYkh3fI3Djr7fNe77oLGxuAxtW1ESppm7uVszZr0++i+NiIlSeEed2Etm3TXGlx6qe5rI1Ki1JaJu2yWO86enbs6RKSgNHOX1NL9w9DUpLaNSEQp3MtdWNuma9fwn62rU9tGJKIU7uUum5uWfetb6ffRzF6kKBTuEi5sZv/EE+E/++STmtmLFIlOqEq4bE7IXnhh7uoQkQ7RzF3yZ86c8HG1bETyRuEu2Qlr23zzm+E/q5aNSN4o3CU72ZyQDeOumb1IFhTukl+dvanZoEGa2YtkQeEu+dXZmf0JJ6R/b83sRVJSuEs0TZ8ePn7eeZrZi4RQuEvxdLZlAzB3bvp9NLOXMqZ17lI82Zx0/eQTqAiZm1xzjWb2UtY0c5foCpvZhz2EBOCBB9K/v2b2EmOauUt0ZTOz37IFundPPX7HHZrZS6xp5i6lK2xm361b+M+OG5f+/TWzlxKmcJfSlc0FVCtXho8/9JBm9lLSFO4SX2Ez+/r68J/94Q/DxzWrl4hTuEt8ZTOzX7IkfFyzeok4hbuUr7CZ/VFHZffemtlLkSncpXzl66ZnRxyRfmav8Jc8SxvuZvawmW0ws0Upxs3M7jaz5Wa2wMyG575MkSLo7BW0Rx4ZPr5xo9o6kneZzNynAaNCxs8ADk9+jQXuy74skQjo7Mz+mWfCxw86KP1na2YvWUob7u4+B9gUsssY4N884S2gxsz65apAkUjK5r44kyeHjz/4oGb2krVc9NzrgNaLhlclt4nEVzb9+vHjw8fHjk3/HprZSxoFPaFqZmPNbJ6Zzdu4cWMhP1qksLKZ2X/4Yfj4SSeFz+wV/EJuwn01MKDV6/rktnbcfaq7N7h7Q21tbQ4+WiSi0s3sw8L/sMPC37tr1/BxtXSE3IT7LODy5KqZE4Gt7r42B+8rEl/ZtHXeeCO7z9bMviykvSukmT0GjAT6mNkq4KdAFYC73w/MBkYDy4EvgP+Tr2JFykbfvsEz7UzaOmH69ctsDX6qz872GgApmLTh7u4Xpxl34O9yVpGI5C9ETz8dHnkk9fiUKQr/mNAVqiKlqLMnbKdNCx+/9trw8R071NMvEQp3kVIU1rPPZqXOhg3h4z17pn8P9fQjQeEuEjfZnKxNt4rtppvCx889V8s0I0LhLlJuspnZ/+Qn4ePZ3ipZ4Z8zCneRcpPNGvx03n+/83X9938r/HNI4S4i+8pn+Ic5+eTw8b17Ff4doHAXkY7J133wn38+fLy6Ov17aCXPlxTuIpJbnZ3Zjwq7szgwYUL4+AknhI9DWc3sFe4iklv5WqZ5yy3h4717h4//zd+U1UoehbuIFE4++/kvvhg+nq7tE7N+vsJdRKIjn+G/Nov7Gd50U8mFv8JdREpHsVbyTJoUPn7//ZEL/7Q3DhMRKRn5unHZzp3hq3Wuuir85x9/vOAreTRzF5Hy0dmZfffu4eMrV4aPXxx6c928ULiLSPnI10qe+vrw8YULO15rltSWERGB9C2dbB6gcswxnaspCwp3EZFM5DP880DhLiKSCxELf4W7iEghFPgRhDqhKiISQwp3EZEYUriLiMSQwl1EJIYU7iIiMaRwFxGJIYW7iEgMKdxFRGJI4S4iEkMZhbuZjTKzD8xsuZlNDBgfaGavm9m7ZrbAzEbnvlQREclU2nA3s0rgHuAMYAhwsZkNabPbj4En3X0YcBFwb64LFRGRzGUyc/86sNzdP3L3PcDjwJg2+ziwf/L7XsCa3JUoIiIdlUm41wGtHzOyKrmttUnApWa2CpgN/H3QG5nZWDObZ2bzNm7c2IlyRUQkE7k6oXoxMM3d64HRwL+bWbv3dvep7t7g7g21tbU5+mgREWkrk3BfDQxo9bo+ua21HwBPArj7b4HuQJ9cFCgiIh2XSbjPBQ43s0PMrCuJE6az2uzzR+DbAGZ2FIlwV99FRKRI0oa7uzcCVwMvAktJrIpZbGY3m9lZyd2uBX5oZvOBx4Ar3N3zVbSIiITL6ElM7j6bxInS1ttubPX9EmBEbksTEZHO0hWqIiIxpHAXEYkhhbuISAwp3EVEYkjhLiISQwp3EZEYUriLiMSQwl1EJIYU7iIiMaRwFxGJIYW7iEgMKdxFRGJI4S4iEkMKdxGRGFK4i4jEUEb3cxcRkfRmvruan7/4AWu27KR/TTXjTz+Cs4fVZTyeSwp3EZGkbMJ55ruruX7GQnbubQJg9ZadXD9jIQBnD6tLO55rVqyn4TU0NPi8efOK8tkiUrqynR2nGm8bvgDVVZXceu6xnD2sjqfnreTHzyxi197mL8e7VlbwvRMHcEz/Gm5+dglbd+5tV2+3LhUc3X9/FqzaSmNz+7ytq6nmNxNPyfj3b2bvuHtD2v0U7iJSSLmcHcO+AZzZ+AJ2tgnoc4b15/lF69i2q7FdvRUGXSor2NPY3G4sU984rA//s/zTwDEDPr7trzJ+L4W7iORNvmbHqcZvHnM0J331QM655002fr67XT09ulZy+tEHM3vR2n1m1i0qDPbr1iUwvDPxf08+lAfmfBQ4ZsCvx4/kwgfeYt22Xe3GW2bmI257jdVbdqYcz1Sm4a6eu0gZKnRveeKMBWzasZv73/hon+AG2Lm3iRufWcSy9dt55M0VgePjn14Q+vvZsaeJ363YFBjsAM0O5w6vZ9qbKwLHDejXqztrtgaH8/Wjj+LZBWsDw7l/TTWDDuzBxDOODPyHafzpRwAw/vQjQsdzTUshRWJo5rurGXHbaxwy8TlG3PYaM99dvc/Y9TMWsnrLTpw/hXPLPkHjE6YvYMrLHzBn2UZufnZxYABPnLGASx58i3FPzW83vmtvMzc/u5QN29vPugG27Wpk6pyP2LGnKXAc4PbzjqV3j66BY3U11fzPhFOoq6lOOT7prKNTjvevqea6UUdSXVW5z/a24Rw2fvawOm4991jqaqqx5Ge2/I8kk/FcU1tGJKLy0fo449iDOXny66zf1j5ku3Wp4LCD9uP9tdto6mQsNAw6gHmfbE45fsBXqtj8RfuTjv17dec3E0/hG7e/Htq6yE3PPXw8KksZU1HPXaTICn3isFuXCn74zUN49Hcr2bRjT7t6KizRngjz7SMP4tX3N6Qcn37VSVz1H78PnIFn0ltO1ZrINHxbjk0+VsuUCoW7SJ5lE84z3lnFDTMXtllWZ3z3hAEM6deL219Yytad7U/+da1MzK4/WL+dpnRJHeCa7xzOtDdXsCVg9pzpib9ymB1HmcJdJAc61vqo4CdnDmHogAO47F/f5rOA2XOXCmO/7l0CwzVT3znqIF5Zmnp2XduzGxtDZtbZhjPEf3YcZQp3kSylCrlJfz2EX7y0LHBJXiYuP2kQ//bbTwLHDPjt9d/mnHt/w9oUKzeybX20/N4UzqUpp0shzWwUcBdQCTzk7rcF7PNdYBLgwHx3v6RDFYvkQTYhNvmF9wNXhUxILvtL5d7vDeenzywODP+6mmpuHnMMry7dkHJZ3cG9ujNhVOeX1bXUH/b7PntYXWhYpxuX6Esb7mZWCdwDnAqsAuaa2Sx3X9Jqn8OB64ER7r7ZzA7KV8EirWW7HnvijAVf9r1Xb9nJtU/N519e+5Ade5oCZ84tevfoGnjSsq6mmtHH9mNPY3NWa57TBXQm4wrn8pa2LWNmJwGT3P305OvrAdz91lb7TAaWuftDmX6w2jKSiWxOWv7Fba+yZkv7gO7WpYJBB36FD9d/TtCf/qpK46+P68/LS9ezPeCKRrU+pJhy1nM3s/OBUe5+ZfL1ZcCfu/vVrfaZCSwDRpBo3Uxy9xcC3mssMBZg4MCBx3/ySXDfUcpHNuE94rZXWZ0ivPv16s6Kz75I+bmnDenLS0vWB4613Osj21UfIvlQ6NsPdAEOB0YC9cAcMzvW3be03sndpwJTITFzz9FnS4kKa5uMGdqf21L0vK97egFTXl4WGOwAuxubOaauF59+vofPdwfPvKde3pDypGT/5FWMan1IKcsk3FcDA1q9rk9ua20V8La77wU+NrNlJMJ+bk6qlEjrbPvh5y8Gh/e1T81nwvQF7E5xF749Tc0MHVDDph2pw/tfLhmecubdkXt9KMClVGVyb5m5wOFmdoiZdQUuAma12WcmiVk7ZtYH+DMg+BZqUnJyfZ+ScU/N57Qpb6SceTc1O9//i8H0qg6ee9TVVHP3xcP4p7OPKal7fYgUUkbr3M1sNHAniX76w+5+i5ndDMxz91lmZsAdwCigCbjF3R8Pe0+dUI2OzvS9fzbmaI6u68UlD74VeK+Qygrj4P27s3brzsBL3qsqjarKCr4IuFFUphfbpKtdJI50EZNkJOxKyxGH9eH8+37b6Yt1zh1ex4zft+3gJRjwywuHKrxFOkj3c5cvpQrIHbsb+afnlgT0vZu54VeL0r7vXRcN5Zbngm/jWldTzZTvDuXtjzalPGmZi4ttRCSYwj3mglakXPvUfCa/8D7rtu0KvUvgHRd8jVtmL015sc6YoXW4k/XFOgpvkdxTuMdE0Oz8zOP6Bc7Mm5qdz3bs4eq/PIz/fPuPgTe4qqup5rzj66mssLxeSSki+aGeewwE9c0rzejaxfZ5EHBrmV6o0/L+CmeRaFDPPWbCAvbW55e2n527AxX07lHFph0BT77J8EKdln0U5iKlReFeAoL65hOmL+ClxetYuXln4CPTAHbtbeLWc4/VhToiZUgPyC4BP3/xg3Yz892NzcxetI6qSmP/7sH/RresSNGFOiLlRzP3iNu6c2/gUkJI9M1n/L8RaS+z18xcpPwo3CNi3556dy5oGMDqzTv5rwVrUv5MR/rmIlJeFO4R0L6nvos7X/mQqkrj/OPr6d+rmnt//Qf1zUUkYwr3InP3wLXoAH3268at5x4HwIDeX9HMXEQypnAvkLZLGa8aeSi79jbz+NyVfPp5+4uIANa1esybZuYi0hEK9wIIWsr445mLARg+sIaa6iq27Ey9Fl1EpKMU7jkSdJHRWV/rz7IN2/nprEWBbZeDenbLaLWLiEhHKdxzIPDmXE++x49+tZAdAfcrb7ExeTdFrXYRkVxTuOdA0OPimhyaHX5xwdf4+YvvB15F2rrtop66iOSSwr0D2rZerj31z6jqUpHycXG79jZx/vH1dElzZ0URkVxTuGco1X3RHehSYTQG3BhdFxmJSLEo3DMUdH8XB3r3qOLHo4fwo5mLdJGRiESGwr2VoBUv3xnSlxcWrUt5f5fNO/Zy7vH1VFSYZuYiEhkK96RUK17MoLEZKiuMpjStF4W5iERFWYV72AMvJr8QvOKlR1UlT/zg6/zxsy+44VfhrRcRkagom3APmplPnL6Atz76jE079rBma/CKly/2NHH8oN4cP6g3Zmq9iEhpKJtwDzohuqsxcW+Xfr2606NrZeAFR1qLLiKlKFbhHtR2GTO0P4vXbAt94MWbE0/hmffWaC26iMRGbMI9qO0y7qn53PRfi9n8RfubcrXoX1ONmWktuojESmzCPajt0tjsfLGnidvPO5a9Tc4tzy3VWnQRKQsZPSDbzEaZ2QdmttzMJobsd56ZuZk15K7EzKxJ0XbZ09jMhScM5NITB+lB0SJSNtLO3M2sErgHOBVYBcw1s1nuvqTNfj2BfwDezkehYd5ft43KNLcAAM3MRaR8ZDJz/zqw3N0/cvc9wOPAmID9fgbcDgSvKcyTp99Zxdn3/Ibqqgq6dtn3t6MToiJSrjLpudcBK1u9XgX8eesdzGw4MMDdnzOz8Tmsbx+tV8P069Wdgb2/wlsfb+LEQ3tz98XDeHP5ZzohKiJCDk6omlkFMAW4IoN9xwJjAQYOHNihz2m7GmbN1l2s2bqLU486iPsuPZ4ulRVqu4iIJGXSllkNDGj1uj65rUVP4Bjg12a2AjgRmBV0UtXdp7p7g7s31NbWdqjQoNUwAEvWbqdLZUbnhUVEykYmqTgXONzMDjGzrsBFwKyWQXff6u593H2wuw8G3gLOcvd5uSw01WqYVNtFRMpZ2nB390bgauBFYCnwpLsvNrObzeysfBfYovWql0y2i4iUs4x67u4+G5jdZtuNKfYdmX1Z7Y0//QjdHkBEJEMlc4Wqbg8gIpK5kgl30EVIIiKZ0jITEZEYUriLiMSQwl1EJIYU7iIiMaRwFxGJIXNvf5vcgnyw2Ubgk5Bd+gCfFqicjlJtnaPaOke1dU5caxvk7mnv31K0cE/HzOa5e8Ef+pEJ1dY5qq1zVFvnlHttasuIiMSQwl1EJIaiHO5Ti11ACNXWOaqtc1Rb55R1bZHtuYuISOdFeeYuIiKdFLlwN7NRZvaBmS03s4nFrqc1M1thZgvN7D0zy+nDSDpRy8NmtsHMFrXa1tvMXjazD5O/HhCh2iaZ2erksXvPzEYXqbYBZva6mS0xs8Vm9g/J7UU/diG1Ff3YmVl3M/udmc1P1nZTcvshZvZ28u/rE8kH+kSltmlm9nGr4za00LW1qrHSzN41s2eTr/N/3Nw9Ml9AJfAH4FCgKzAfGFLsulrVtwLoU+w6krWcDAwHFrXaNhmYmPx+InB7hGqbBIyLwHHrBwxPft8TWAYMicKxC6mt6McOMGC/5PdVwNskHqn5JHBRcvv9wFURqm0acH6x/8wl6/pH4FHg2eTrvB+3qM3cvw4sd/eP3H0P8Dgwpsg1RZK7zwE2tdk8Bngk+f0jwNkFLSopRW2R4O5r3f33ye+3k3i6WB0ROHYhtRWdJ3yefFmV/HLgFODp5PZiHbdUtUWCmdUDfwU8lHxtFOC4RS3c64CVrV6vIiJ/uJMceMnM3jGzscUuJkBfd1+b/H4d0LeYxQS42swWJNs2RWkZtWZmg4FhJGZ6kTp2bWqDCBy7ZGvhPWAD8DKJ/2Vv8cSjOKGIf1/b1ubuLcftluRx+6WZdStGbcCdwHVAc/L1gRTguEUt3KPuG+4+HDgD+DszO7nYBaXiif/vRWb2AtwHfBUYCqwF7ihmMWa2HzAduMbdt7UeK/axC6gtEsfO3ZvcfShQT+J/2UcWo44gbWszs2OA60nUeALQG5hQ6LrM7Exgg7u/U+jPjlq4rwYGtHpdn9wWCe6+OvnrBuBXJP6AR8l6M+sHkPx1Q5Hr+ZK7r0/+BWwGHqSIx87MqkiE53+6+4zk5kgcu6DaonTskvVsAV4HTgJqzKzliW5F//vaqrZRyTaXu/tu4P9TnOM2AjjLzFaQaDOfAtxFAY5b1MJ9LnB48kxyV+AiYFaRawLAzHqYWc+W74HTgEXhP1Vws4DvJ7//PvBMEWvZR0twJp1DkY5dst/5r8BSd5/Saqjoxy5VbVE4dmZWa2Y1ye+rgVNJnBN4HTg/uVuxjltQbe+3+sfaSPS0C37c3P16d69398Ek8uw1d/8ehThuxT6LHHBWeTSJVQJ/AH5U7Hpa1XUoidU784HFxa4NeIzEf9H3kujZ/YBEL+9V4EPgFaB3hGr7d2AhsIBEkPYrUm3fINFyWQC8l/waHYVjF1Jb0Y8dcBzwbrKGRcCNye2HAr8DlgNPAd0iVNtryeO2CPgPkitqivUFjORPq2Xyftx0haqISAxFrS0jIiI5oHAXEYkhhbuISAwp3EVEYkjhLiISQwp3EZEYUriLiMSQwl1EJIb+F5QlW+wwxJSfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy_lst3 = [accuracy3[i].tolist()[0] for i in range(len(accuracy3))]\n",
    "# loss_lst3 = [loss_np3[i].tolist()[0] for i in range(len(loss_np3))]\n",
    "# epochs = [i+1 for i in range(num_epochs)]\n",
    "# p3, ax = plot.subplots(1)\n",
    "# ax.plot(epochs, accuracy_lst3, marker = 'o')\n",
    "# ax.plot(epochs, loss_lst3, 'r', marker = 's')\n",
    "# plt.show(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ioni3nPfwEIE"
   },
   "outputs": [],
   "source": [
    "# Choose from one of the above models and improve its performance\n",
    "# Run Baseline CNN\n",
    "# images, labels = extract_data('data/images_train.npy','data/labels_train.npy')\n",
    "# x_train, y_train, x_val, y_val = create_validation(images, labels)\n",
    "# train_set = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "# val_set = torch.utils.data.TensorDataset(x_val, y_val)\n",
    "# train_loader = DataLoader(train_set, batch_size = 64)\n",
    "# validation_loader = DataLoader(val_set, batch_size = 64)\n",
    "\n",
    "# num_epochs = 40\n",
    "# o_cnn= OptimizedNN()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(o_cnn.parameters(), lr = 0.001)\n",
    "\n",
    "# accuracy4,loss_np4,val_accuracy4 = train_val_NN(o_cnn, train_loader, validation_loader, criterion, optimizer,num_epochs)\n",
    "# print(val_accuracy4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-d7081c1eeaa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloss_lst4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss_np4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_np4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mp4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# ax.set_ylim(bottom = 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_lst4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot' is not defined"
     ]
    }
   ],
   "source": [
    "# accuracy_lst4 = [accuracy4[i].tolist()[0] for i in range(len(accuracy4))]\n",
    "# loss_lst4 = [loss_np4[i].tolist()[0] for i in range(len(loss_np4))]\n",
    "# epochs = [i+1 for i in range(num_epochs)]\n",
    "# p4, ax = plot.subplots(1)\n",
    "# # ax.set_ylim(bottom = 0)\n",
    "# ax.plot(epochs, accuracy_lst4, marker = 'o')\n",
    "# ax.plot(epochs, loss_lst4, 'r', marker = 's')\n",
    "# plt.show(p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34807692],\n",
       "       [0.42115385],\n",
       "       [0.50192308],\n",
       "       [0.54615385],\n",
       "       [0.54807692],\n",
       "       [0.59615385],\n",
       "       [0.62115385],\n",
       "       [0.62307692],\n",
       "       [0.61538462],\n",
       "       [0.63653846],\n",
       "       [0.64423077],\n",
       "       [0.66538462],\n",
       "       [0.66538462],\n",
       "       [0.66730769],\n",
       "       [0.67692308],\n",
       "       [0.69807692],\n",
       "       [0.68269231],\n",
       "       [0.72115385],\n",
       "       [0.71730769],\n",
       "       [0.72884615],\n",
       "       [0.72307692],\n",
       "       [0.72884615],\n",
       "       [0.75384615],\n",
       "       [0.725     ],\n",
       "       [0.73653846],\n",
       "       [0.72692308],\n",
       "       [0.73653846],\n",
       "       [0.77115385],\n",
       "       [0.775     ],\n",
       "       [0.77115385],\n",
       "       [0.78076923],\n",
       "       [0.77692308],\n",
       "       [0.78076923],\n",
       "       [0.78076923],\n",
       "       [0.77884615],\n",
       "       [0.79423077],\n",
       "       [0.78076923],\n",
       "       [0.77884615],\n",
       "       [0.79807692],\n",
       "       [0.8       ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val_accuracy4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val_accuracy4[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
